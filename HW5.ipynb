{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aml-spring-19/homework-5-cv5/blob/master/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bKxgsG4-8GCp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "\n",
        "# plots\n",
        "import matplotlib.pyplot\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# processing & model selection\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedShuffleSplit\n",
        "\n",
        "# models\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, BatchNormalization\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# other\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCQfFRpL8kF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Homework 5\n",
        "\n",
        "### Task 1\n",
        "\n",
        "Task is to run a multilayer perceptron with two hidden layers and relu activations, using the Keras Sequential Interface. We also tune for regularization strength and number of hidden units. \n",
        "\n",
        "Importing the data:"
      ]
    },
    {
      "metadata": {
        "id": "3-AIU5gK8YYR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6b46b01f-9a92-4c93-fe97-e4730255d063"
      },
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset('iris')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "EPNx0mJ32SLm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Map the target variable:"
      ]
    },
    {
      "metadata": {
        "id": "H0ymJ4zw3sVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fb5dbaf-65c8-45ce-e3a1-566935dff76a"
      },
      "cell_type": "code",
      "source": [
        "print(df.species.unique())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p3eDZt2C4lwR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mapping = {'setosa': 0, 'versicolor': 1, 'virginica': 2}\n",
        "df.species.replace(mapping, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKMu653l3LMH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split our dataset into training and test sets. "
      ]
    },
    {
      "metadata": {
        "id": "TT7TiTFgFtSQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('species', axis=1), df.species, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Bp1ip1K4tTc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Encode the target:"
      ]
    },
    {
      "metadata": {
        "id": "c3N6qbYR3u5W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_species = len(df['species'].unique())\n",
        "\n",
        "y_train = to_categorical(y_train, num_species)\n",
        "y_test = to_categorical(y_test, num_species)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j8eFwU73E58G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Make our model:"
      ]
    },
    {
      "metadata": {
        "id": "ccuII1y0IN5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee3863d4-5d07-4dc7-cf67-bc4e62480443"
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "nh4g4hb5Ajno",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model(hidden_size, reg_strength, optimizer='adam'):\n",
        "    \"\"\"\n",
        "    Create the model to pass to the Keras Classifier\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential([\n",
        "        Dense(hidden_size, input_shape=(4,), activation='relu',   # first layer\n",
        "              kernel_regularizer=regularizers.l2(reg_strength)),\n",
        "        Dense(hidden_size, activation='relu',                     # second layer\n",
        "              kernel_regularizer=regularizers.l2(reg_strength)),\n",
        "        Dense(3, activation='softmax')                            # output layer\n",
        "    ])\n",
        "    \n",
        "    # compile the above model\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qpIERVKgYF2J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before proceeding any further, we should initialize the cross-validation method to be used in the grid search later on. "
      ]
    },
    {
      "metadata": {
        "id": "Pahcj0WAX6ZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfKn0mTYJB4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "36222464-ca00-49ed-f4f8-ab9142b49b36"
      },
      "cell_type": "code",
      "source": [
        "clf = KerasClassifier(make_model, epochs=10, verbose=0)\n",
        "\n",
        "param_grid = {'hidden_size': [32, 64, 128],\n",
        "              'reg_strength': np.logspace(-3, -1, 5)}\n",
        "\n",
        "grid = GridSearchCV(clf, param_grid=param_grid, cv=sss, n_jobs=-1)\n",
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=3, random_state=42, test_size=0.2,\n",
              "            train_size=None),\n",
              "       error_score='raise-deprecating',\n",
              "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8c6da0a588>,\n",
              "       fit_params=None, iid='warn', n_jobs=-1,\n",
              "       param_grid={'hidden_size': [32, 64, 128], 'reg_strength': array([0.001  , 0.00316, 0.01   , 0.03162, 0.1    ])},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "atFAkxnTJs2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "36c908c6-406b-4796-b674-7de48a841baf"
      },
      "cell_type": "code",
      "source": [
        "print('Best score: {}'.format(np.round(grid.best_score_, 2)))\n",
        "print('Best params: {}'.format(grid.best_params_))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.97\n",
            "Best params: {'hidden_size': 128, 'reg_strength': 0.0031622776601683794}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZZ81ZqHiKn7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05e67a2d-ee51-4395-d3cf-f603c48e4d96"
      },
      "cell_type": "code",
      "source": [
        "score = grid.score(X_test, y_test)\n",
        "print('Test score: {}'.format(np.round(score, 2)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XbLvGZO6S0II",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 2\n",
        "\n",
        "Train a multilayer perceptron (fully connected) on the Fashion MNIST dataset. \n",
        "1. Use 10000 samples from the training set for model selection and to compute learning curves (accuracy vs epochs).\n",
        "2. Compare the following models and plot their learning curves:\n",
        "    - Vanilla Model\n",
        "    - Model using dropout\n",
        "    - Model using batch normalization and residual connections (but no dropout)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JouH89vCTMSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loading the data\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9Tv8VfaTp79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "99c59f75-a657-4caa-ff7b-7a93e4fa5626"
      },
      "cell_type": "code",
      "source": [
        "print('Training size: {}, Test size: {}'.format(X_train.shape[0],X_test.shape[0]))\n",
        "print('Each image has a shape of: {}x{}'.format(X_train.shape[1], X_train.shape[2]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size: 60000, Test size: 10000\n",
            "Each image has a shape of: 28x28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K_LR9acOjbaI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before proceeding with the modeling, we have to process our data accordingly. "
      ]
    },
    {
      "metadata": {
        "id": "bRiA9YkijZe4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reshape X and cast to float\n",
        "X_train = X_train.reshape(60000, 784); X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32'); X_test = X_test.astype('float32')\n",
        "\n",
        "# scale X\n",
        "X_train /= 255; X_test /= 255\n",
        "\n",
        "# encode the target accordingly\n",
        "n_classes = len(np.unique(y_train))\n",
        "y_train = to_categorical(y_train, n_classes); y_test = to_categorical(y_test, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-ZsJhF4irWO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Vanilla Model**\n",
        "\n",
        "We start off by tuning and eventually training our vanilla model. Vanilla models are typically used to describe simple networks with 1 layer, so we'll only look at optimizing the number of hidden units in this case. "
      ]
    },
    {
      "metadata": {
        "id": "4Y0oSA_7jRci",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def make_model(hidden_size):\n",
        "#     \"\"\"\n",
        "#     Create the model to pass to the Keras Classifier\n",
        "#     \"\"\"\n",
        "    \n",
        "#     model = Sequential([\n",
        "#         Dense(hidden_size, input_shape=(784,), activation='relu'),  # first layer\n",
        "#         Dense(3, activation='softmax')                            # output layer\n",
        "#     ])\n",
        "    \n",
        "#     # compile the above model\n",
        "#     model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "#     return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}